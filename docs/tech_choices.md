# Technical choices

## ETL strategy

In the first place, I implemented pl/pgsql stored functions that directly load data into the data warehouse schema:

 - the function for the ***date dimension*** was provided.
 - I decided to create another function for the ***store dimension*** since there were no requirements concerning the size of this table and it was quite easy and quick to implement with arrays of values (for countries and cities), foreach loops (one main for countries and one per country for its cities) and a case when structure.

After that, I proceeded to populate the rest of the tables (product and customer dimension, as well as the sales fact table). I used an external Python script generated by ChatGPT.
My main pain point was the **product_name** field in the product dimension. I refused to give it the trivial 'Product_i' or 'category_subcategory_i' (i being the counter in the for loop) values since I knew it would lower the relevance of the analytical queries I would need to perform afterwards. Therefore I decided to explicitly declare an array of product names that would correspond to each of the chosen categories and I kept one of the few good ideas of ChatGPT which was to handle the subcategory parameter by assigning to it market positioning values : 'Premium', 'Standard' and 'Budget'.

These data were loaded into the staging schema. I then began the transformation phase by dealing with duplication in the **staging.stg_product** table. As described earlier I decided to populate this table using an array of predefined values that I was randomly assigning to the newly created rows. Because of that I ended up with a table where the key (a random 6 digits code) was unique, but the product_name, category and subcategory 3-tuples could be identical.
When loading data from the aforementioned table into the product dimension one I used the **select distinct on** subquery. It ensures that the specified fields combination is unique and that was exactly what I needed in my product dimension table.

!! Another problem that I encountered was the duplication of the product_business_key (though I thought because of the range of numbers (100000, 999999) it won't happen it DID HAPPEN). I proceeded to create a temporary table with unique business keys that I used in the 2 steps of the type 2 SCD (since I needed it twice I could not use a CTE).

Finally I loaded the customer dimension and fact sales tables. I also made sure that the customer's first name as well as the product's name are written to the dimension tables in a capitalized format using the **initcap** function ; the customer's last name was written with the **upper** function.

## SCD strategy

### Type 1

Type 1 could be implemented using the following query depicting the situation when the staging area table was altered (new load of products for instance) and the data warehouse dimension table is hence updated:

    UPDATE dwh.dim_product d
    SET
    d.product_name = s.product_name,
    d.category = s.category,
    d.subcategory = s.subcategory
    FROM staging.stg_product s
    WHERE d.product_business_key = s.product_business_key
    AND (
    d.product_name IS DISTINCT FROM s.product_name
    OR d.category IS DISTINCT FROM s.category
    OR d.subcategory IS DISTINCT FROM s.subcategory
    );


Another example of the overwrite type can be the following insert statement (the business key in the dwh schema has the UNIQUE constraint, thus when inserting new rows from the staging area table if identical business keys are found new values will be inserted)  :

    INSERT INTO dwh.dim_product (product_business_key, product_name, category, subcategory)
    SELECT DISTINCT ON (product_name, category, subcategory)
    product_business_key,
    initcap(product_name),
    category,
    subcategory
    FROM staging.stg_product
    ORDER BY product_name, category, subcategory, load_timestamp DESC
    ON CONFLICT (product_business_key) DO UPDATE
    SET product_name = EXCLUDED.product_name,
    category = EXCLUDED.category,
    subcategory = EXCLUDED.subcategory;
    WHERE
    dwh.dim_product.product_name IS DISTINCT FROM EXCLUDED.product_name,
    dwh.dim_product.category IS DISTINCT FROM EXCLUDED.category,
    dwh.dim_product.subcategory IS DISTINCT FROM EXCLUDED.subcategory;

### Type 2

Type 2 SCD is implemented for the following dimensions : **product, customer**. For the store dimension my idea was to stay with type 1 SCD since there's no point in saving the old data, for ex. if the store name changes, it would be more relevant to show the new logo when performing analytical queries ; and since the data from the store dimension table is connected to the sales table via the primary key and the PK does not change, it won't affect any of the established relationships/queries.

P.S : putting type 2 SCD can still be better even for the store dimension since if for instance there's a need to compare sales from previous years for a given store before its rebranding type 2 SCD makes it possible. Thus, I would say that I chose to implement type 1 SCD for the store dimension in order to practice applying different types of it.

#### Major steps in type 2 SCD explanation

 - **update** rows that was changed by setting *current* flag to False as well as *valid till* field. This operation would come in hand when detecting rows that need to be updated in the next step;
 - **insert** both new rows and those where changes occurred. When inserting a new version of a row, a join is performed in order to retrieve the latest version value and increment it by 1. Last but not least, a check is performed on the fields of each row to ensure that only those lines where changes was made are inserted in the table.
